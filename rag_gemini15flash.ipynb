{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyVJWydWh3ZstJ2Vvi51EX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abenfaddoul/Rag/blob/main/rag_gemini15flash.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a RAG Application in 10 min with Gemini 1.5 Flash and Hugging Face"
      ],
      "metadata": {
        "id": "8GaR1Uf3YjGi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WnQlWPaJOwwm"
      },
      "outputs": [],
      "source": [
        "# We install the necessary libraries\n",
        "!pip install langchain sentence-transformers\n",
        "!pip install langchain-community\n",
        "!pip install langchain-huggingface\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To split the documents into chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# To use MyScale as a vector database\n",
        "from langchain_community.vectorstores import MyScale\n",
        "# To use Hugging Face for embeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "# To load PDF\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "# To use Gemini 1.5 Flash\n",
        "import google.generativeai as genai\n",
        "# To use os\n",
        "import os"
      ],
      "metadata": {
        "id": "ekPsiUhtO8VJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the vector database connections\n",
        "os.environ[\"MYSCALE_HOST\"] = \"Your_Host\"\n",
        "os.environ[\"MYSCALE_PORT\"] = \"443\"\n",
        "os.environ[\"MYSCALE_USERNAME\"] = \"Your_Username\"\n",
        "os.environ[\"MYSCALE_PASSWORD\"] = \"Your_Password\"\n",
        "\n",
        "# Setting up the API key for the Gemini 1.5 Flash\n",
        "genai.configure(api_key=\"\")\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n"
      ],
      "metadata": {
        "id": "csVyJVUUPcvy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We select Docs & provide path\n",
        "loader = PyPDFLoader(\"Your_pdf\",)\n",
        "\n",
        "# We load the documents\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "1T6YD0SqQaRS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We split the loaded documents into manageable chunks\n",
        "character_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "docs = character_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "dn0x5Fw0RPXI"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use a Hugging Face embedding model to create embeddings for our document chunks\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
        "docsearch = MyScale(embedding=embeddings)\n",
        "docsearch.add_documents(docs)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AL_zBGhmRXd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We test the search functionality to ensure that embeddings and vector store are working correctly\n",
        "query = \"Text to search or question\"\n",
        "docs = docsearch.similarity_search(query, 1)\n",
        "docs"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QX0LX78eV5Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We prepare the context from the retrieved document\n",
        "rag_context = \"\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "uS9x2jlYW2sB"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We generate the response based on the provided context\n",
        "prompt = \"Your prompt\"\n",
        "contents = [\n",
        "    rag_context,\n",
        "    prompt,\n",
        "]\n",
        "response = model.generate_content(contents)\n",
        "response.text"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ho-C-uFWXG2l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}